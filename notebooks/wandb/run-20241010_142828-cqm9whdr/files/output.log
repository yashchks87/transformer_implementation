100%|██████████| 817/817 [07:17<00:00,  1.87batch/s, loss=2.84e+3]
100%|██████████| 9/9 [00:17<00:00,  1.89s/batch, loss=24.7]
Epoch 0/50 | Train Loss: 3.476829682890613 | Val Loss: 2.7436897224850125
100%|██████████| 817/817 [07:13<00:00,  1.89batch/s, loss=2.02e+3]
100%|██████████| 9/9 [00:17<00:00,  1.95s/batch, loss=19.3]
Epoch 1/50 | Train Loss: 2.467413495336927 | Val Loss: 2.1449731720818415
100%|██████████| 817/817 [07:09<00:00,  1.90batch/s, loss=1.63e+3]
100%|██████████| 9/9 [00:17<00:00,  1.91s/batch, loss=16.2]
Epoch 2/50 | Train Loss: 1.991557378809776 | Val Loss: 1.80077682601081
100%|██████████| 817/817 [07:15<00:00,  1.87batch/s, loss=1.37e+3]
100%|██████████| 9/9 [00:18<00:00,  2.06s/batch, loss=14]  
Epoch 3/50 | Train Loss: 1.6803480036547602 | Val Loss: 1.5569408999549017
 92%|█████████▏| 749/817 [06:31<00:33,  2.03batch/s, loss=1.09e+3]Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f0300836ac0>
Traceback (most recent call last):
  File "/databricks/python/lib/python3.11/site-packages/torch/utils/data/dataloader.py", line 1479, in __del__
    self._shutdown_workers()
  File "/databricks/python/lib/python3.11/site-packages/torch/utils/data/dataloader.py", line 1443, in _shutdown_workers
    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)
  File "/usr/lib/python3.11/multiprocessing/process.py", line 149, in join
    res = self._popen.wait(timeout)
          ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/multiprocessing/popen_fork.py", line 40, in wait
    if not wait([self.sentinel], timeout):
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/multiprocessing/connection.py", line 935, in wait
    ready = selector.select(timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/selectors.py", line 415, in select
    fd_event_list = self._selector.poll(timeout)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
KeyboardInterrupt:
 92%|█████████▏| 749/817 [06:35<00:35,  1.90batch/s, loss=1.09e+3]

KeyboardInterrupt
Reading CSV file...
Splitting is completed. Train size: 98010, Val size: 990, Test size: 1000
Datasets are created.
DataLoaders are created.

100%|██████████| 584/584 [07:21<00:00,  1.32batch/s, loss=2.13e+3]
100%|██████████| 6/6 [00:18<00:00,  3.13s/batch, loss=17.5]
Epoch 0/50 | Train Loss: 3.645676612037502 | Val Loss: 2.9117236932118735
  0%|          | 0/584 [00:17<?, ?batch/s]
